<h2>Troubleshooting Parallelism</h2>
<p>There are a number of reasons why test splitting across parallel containers may be behaving unexpectedly. Our documentation on <a href="https://circleci.com/docs/2.0/parallelism-faster-jobs/">running tests in parallel</a> has a wealth of information to help you, too.<br><br></p>
<h3>Save Artifacts</h3>
<p>The <code><a href="https://circleci.com/docs/2.0/configuration-reference/#store_test_results">store_test_results</a></code> step will ensure test timings are saved, but it doesn't allow for easy debugging. You may also want to upload your tests via <code><a href="https://circleci.com/docs/2.0/configuration-reference/#store_test_results">store_artifacts</a></code> to visually verify the number of tests being run.<br><br></p>
<h3>Echo Test Results</h3>
<p>Similar to saving artifacts, here is an example of how you can implement a clean test split command and also echo out the test data.</p>
<p><code>
        TESTFILES=$(circleci tests glob "test/**_test.rb" | circleci tests split --split-by=timings) <br>
        echo ${TESTFILES}<br>
        # bundle exec rake knapsack_pro:minitest<br>
        bundle exec rspec --format progress \<br>
        --format RspecJunitFormatter \<br>
        -o test/reports/rspec.xml \<br>
        -- ${TESTFILES}<br>
    </code></p>
<p>You can find a few examples on <a href="https://discuss.circleci.com/search?q=testfiles%3D%20category%3A48" target="_blank" rel="noopener">our community forum<br><br></a></p>
<h3>Varying Parallelism</h3>
<p>Different amounts of parallelism may have a great effect on your tests, depending on the way they are written. It may also help you identify particular tests that are causing problems repeatedly.<br><br></p>
<h3>Timing data</h3>
<p>Timing data will be saved upon a successful "green" build. When builds start, we automatically pick the latest job's test results in the same branch jobs. If there is no data in the same branch, we select the latest job's test results in the same project's jobs. You can see which job's test results we picked in the <strong>Downloading previous test results</strong> step.</p>
<p><img src="https://support.circleci.com/hc/article_attachments/6213956645915/Screen_Shot_2022-05-27_at_15.39.50.png" alt="Screen_Shot_2022-05-27_at_15.39.50.png"><br><br>You can also inspect your timing data, which can be found in the <span><em>$CIRCLE_INTERNAL_TASK_DATA/circle-test-results/results.json</em> file.<br><br>For example:<br><br></span></p>
<pre><span>- run:<br>    name: Check out previous test metadata<br>    command: |<br>      cat "${CIRCLE_INTERNAL_TASK_DATA}/circle-test-results/results.json" | jq .</span></pre>
<h3>
    <strong><br><img src="https://support.circleci.com/hc/article_attachments/6213979386139/Screen_Shot_2022-05-27_at_15.53.14.png" alt="Screen_Shot_2022-05-27_at_15.53.14.png"><br><br></strong>Variable Length Tests
</h3>
<p>You may have a test or suite of tests that will vary greatly in their completion time, either on purpose, or for a number of other reasons. This is common with UI or Unit Testing.<br>If your test timing varies with every test, the CircleCI splitting system will never be able to determine valid timing data.<br><br></p>
<h3>Alternative Test Splitting Methods</h3>
<p>Our documentation has more information about splitting tests. You can find it <a href="https://circleci.com/docs/2.0/parallelism-faster-jobs/#other-ways-to-split-tests" target="_blank" rel="noopener">here</a></p>